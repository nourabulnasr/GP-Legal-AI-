from llm.lfm_model import load_model

tokenizer, model = load_model()
print("Model loaded successfully")
